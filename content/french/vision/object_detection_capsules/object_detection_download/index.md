---
title: "TÃ©lÃ©charger le rÃ©seau prÃ©-entraÃ®nÃ©"
menu:
  main:
    name: "TÃ©lÃ©charger le rÃ©seau prÃ©-entraÃ®nÃ©"
    weight: 3
    parent: "capsulesTF2"
---


| Classe de capsule  | &emsp;DurÃ©e recommandÃ©e |
|:-------------------|:------------------|
| Info  &emsp;  â„¹ï¸  |&emsp; 5 min      |


## ğŸ’ PrÃ©requis

* Quelques notions de base d'utilisation du terminal
* Quelques notions sur les rÃ©seaux de neurone
* Capsule sur l'installation des modules
* Capsule sur la mise en place de l'arborescence de travail

## ğŸ“ Acquis d'apprentissage

* Mise en place d'un rÃ©seau, ici, prÃ©-entraÃ®nÃ©

## Introduction 

Construire son propre modÃ¨le et l'entraÃ®ner peut prendre plusieurs jours 
et requiert une quantitÃ© de donnÃ©es d'entraÃ®nements trÃ¨s importantes. 
Une solution est d'entraÃ®ner un modÃ¨le dÃ©jÃ  existant et, bien sur, 
compatible avec l'architecture de destination (TPU, ARM...). Cette
technique est connue sous le nom de **Transfert Learning** ou parfois **Fine Tuning**.
En effet, le **Transfert Learning** permet de partir d'un modÃ¨le dÃ©jÃ  entrainÃ© pour 
une tÃ¢che spÃ©cifique et de complÃ©ter l'entraÃ®nement avec de nouvelles classes 
en utilisant une base de donnÃ©es plus petites.
Deux possibilitÃ©s existent pour faire cela : 
* Re-entraÃ®ner tout le modÃ¨le (en ajustant les poids Ã  travers le rÃ©seau), 
* Enlever la derniÃ¨re couche qui effectue la classification et entraÃ®ner une nouvelle couche 
qui reconnaÃ®t des nouvelles classes.

## TÃ©lÃ©charger le rÃ©seau prÃ©-entraÃ®nÃ©

Plusieurs familles de rÃ©seaux dÃ©diÃ©s Ã  la dÃ©tection dâ€™objets sont proposÃ©s sur le site  [TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md), parmi lesquellesÂ :

* Les rÃ©seaux __R-CNN__ (_Region-based Convolutional Neural Network_) : basÃ©s sur le concept de __recherche ciblÃ©e__ (_selective search_). 
![R-CNN](img/R-CNN.png)(source: https://arxiv.org/pdf/1311.2524.pdf)<br>
Au lieu dâ€™appliquer la sous-fenÃªtre d'analyse Ã  toutes les positions possibles dans lâ€™image, lâ€™algorithme de recherche ciblÃ©e gÃ©nÃ¨re 2000 propositions de rÃ©gions dâ€™intÃ©rÃªts oÃ¹ il est le plus probable de trouver des objets Ã  dÃ©tecter. Cet algorithme se base sur des Ã©lÃ©ments tels que la texture, lâ€™intensitÃ© et la couleur des objets quâ€™il a appris Ã  dÃ©tecter pour proposer des rÃ©gions dâ€™intÃ©rÃªt. Une fois les 2000 rÃ©gions choisies, la derniÃ¨re partie du rÃ©seau calcule la probabilitÃ© que lâ€™objet dans la rÃ©gion appartienne Ã  chaque classe. Les versions __Fast R-CNN__ et __Faster R-CNN__ rendent lâ€™entraÃ®nement plus efficace et plus rapide.

* Les rÃ©seaux __SSD__ (_Single Shot Detector_) : font partie des dÃ©tecteurs considÃ©rant la dÃ©tection dâ€™objets comme un problÃ¨me de rÃ©gression. L'algorithme __SSD__ utilise dâ€™abord un rÃ©seau de neurones convolutif pour produire une carte des points clÃ©s dans lâ€™image puis, comme __Faster R-CNN__, utilise des cadres de diffÃ©rentes tailles pour traiter les Ã©chelles et les ratios dâ€™aspect.

La diffÃ©rence entre "Faster R-CNN" et SSD est quâ€™avec R-CNN on rÃ©alise une classification sur chacune des 2000 fenÃªtres gÃ©nÃ©rÃ©es par lâ€™algorithme de recherche ciblÃ©e, alors quâ€™avec SSD on cherche Ã  prÃ©dire la classe ET la fenÃªtre de lâ€™objet en mÃªme temps. Cela rend SSD plus rapide que "Faster R-CNN", mais Ã©galement moins prÃ©cis.

Dans le tableau du site [TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md), les performances des diffÃ©rents rÃ©seaux sont exprimÃ©es en _COCO mAP (Mean Average Precision)_, mÃ©trique couramment utilisÃ©e pour mesurer la prÃ©cision dâ€™un modÃ¨le de dÃ©tection dâ€™objets. Elle consiste Ã  mesurer la proportion de dÃ©tections rÃ©ussies sur des images dÃ©jÃ  annotÃ©es du dataset COCO (Common Object in CONtext)
qui contient 200 000 images annotÃ©es avec 80 objets diffÃ©rents. Cette mesure sert de rÃ©fÃ©rence pour comparer la prÃ©cision de diffÃ©rentes architectures de dÃ©tection dâ€™objets (plus dâ€™informations sur _mAP_ dans la lecture [2]).


ğŸ“¥ Pour le travail de dÃ©tection des faces des cubes dans les images fournies par la camÃ©ra du robot Ergo Jr tu peux tÃ©lÃ©charger le rÃ©seau `Faster R-CNN ResNet50 V1 640x640` sur le site [TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md) (~203 Mo).

__Attention ! Si le rÃ©seau doit Ãªtre converti en **.tflite** par la suite afin d'Ãªtre exportÃ© sur des architectures 
plus lÃ©gÃ¨res comme sur Raspberry Pi, un rÃ©seaux SSD tel que **SSD MobileNet V2 FPNLite** est
prÃ©fÃ©rable.__ (cf. Capsule **Convertir un rÃ©seau Tensorflow en TFLite**).

Une fois tÃ©lÃ©chargÃ©e, il faut extraire l'archive TGZ au bon endroit dans l'arborescence de travail :
```bash
# From within tod_tf2/
(tf2) jlc@pikatchou $ tar xvzf ~/TÃ©lÃ©chargements/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz -C pre_trained
```
puis crÃ©er le dossier correspondant `faster_rcnn_resnet50_v1_640x640_coco17_tpu-8` dans le dossier `training/faces_cubes` :
```bash	
# From within tod_tf2/
(tf2) jlc@pikatchou $ mkdir training/faces_cubes/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8
```
On vÃ©rifie :
```bash
# From within tod_tf2/
(tf2) jlc@pikatchou $ tree -d pre_trained
pre_trained
â””â”€â”€ faster_rcnn_resnet50_v1_640x640_coco17_tpu-8
    â”œâ”€â”€ checkpoint
    â””â”€â”€ saved_model
        â””â”€â”€ variables
        
(tf2) jlc@pikatchou $ tree -d training
training
â””â”€â”€ faces_cubes
    â””â”€â”€ faster_rcnn_resnet50_v1_640x640_coco17_tpu-8
```